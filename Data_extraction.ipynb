{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the api keys\n",
    "fred_api_key = os.getenv('FRED_API_KEY')\n",
    "bls_api_key = os.getenv('BLS_API_KEY')\n",
    "\n",
    "fred=Fred(api_key=fred_api_key)\n",
    "\n",
    "# date range of the datasets\n",
    "start_date = '1990-01-01'\n",
    "end_date = '2025-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of datasets info\n",
    "df_sets = pd.read_csv('Data_info.csv', delimiter=';')\n",
    "\n",
    "# general info of S&P500 composition and BLS endpoint\n",
    "sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "data_table = pd.read_html(sp500_url)\n",
    "\n",
    "BLS_ENDPOINT = \"https://api.bls.gov/publicAPI/v2/timeseries/data/\"\n",
    "\n",
    "# Creating the object with S&P500 ticker\n",
    "sp500_index = yf.Ticker('^GSPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P500 index\n",
    "historical_index_data = sp500_index.history(start=start_date, end=end_date)\n",
    "\n",
    "df_SP500 = historical_index_data[['Close']].reset_index()\n",
    "\n",
    "df_SP500['Date'] = pd.to_datetime(df_SP500['Date']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Datasets\\Bank_Credit_All_Commercial_Banks.csv\n",
      "Saved: Datasets\\10Year_Real_Interest_Rate.csv\n",
      "Saved: Datasets\\Commercial_Real_Estate_Prices_for_United_States.csv\n",
      "Saved: Datasets\\Consumer_Loans_Credit_Cards_and_Other_Revolving_Plans_All_Commercial_Banks.csv\n",
      "Saved: Datasets\\Market_Yield_on_US_Treasury_Securities_at_10Year_Constant_Maturity_Quoted_on_an_Investment_Basis.csv\n",
      "Saved: Datasets\\Consumer_Price_Index_for_All_Urban_Consumers.csv\n",
      "Saved: Datasets\\Continued_Claims_Insured_Unemployment.csv\n",
      "Saved: Datasets\\Delinquency_Rate_on_Credit_Card_Loans_All_Commercial_Banks.csv\n",
      "Saved: Datasets\\Federal_Funds_Effective_Rate.csv\n",
      "Saved: Datasets\\Gross_Domestic_Product.csv\n",
      "Saved: Datasets\\Households_Owners_Equity_in_Real_Estate_Level.csv\n",
      "Saved: Datasets\\M2.csv\n",
      "Saved: Datasets\\Median_Consumer_Price_Index.csv\n",
      "Saved: Datasets\\NASDAQ_Composite_Index.csv\n",
      "Saved: Datasets\\Personal_Saving_Rate.csv\n",
      "Saved: Datasets\\Real_Estate_Loans_All_Commercial_Banks.csv\n",
      "Saved: Datasets\\Real_Gross_Domestic_Product.csv\n",
      "Saved: Datasets\\Sticky_Price_Consumer_Price_Index_less_Food_and_Energy.csv\n",
      "Saved: Datasets\\Total_Unemployed_Plus_All_Persons_Marginally_Attached_to_the_Labor_Force.csv\n",
      "Saved: Datasets\\Unemployment_Level.csv\n",
      "Saved: Datasets\\Unemployment_Rate.csv\n",
      "Saved: Datasets\\Population.csv\n",
      "Saved: Datasets\\Nonfarm_Business_Sector_Labor_Productivity_Output_per_Hour_for_All_Workers.csv\n",
      "Saved: Datasets\\Real_Earnings_employed_full_time.csv\n",
      "Saved: Datasets\\Total_Reserves_Bank.csv\n",
      "Saved: Datasets\\Term_Funding_Program.csv\n",
      "Saved: Datasets\\Discount_Window.csv\n",
      "Saved: Datasets\\Federal_Debt_Total_Public_Debt.csv\n",
      "Saved: Datasets\\Government_current_expenditures_Income_security.csv\n",
      "Saved: Datasets\\Government_social_benefits_to_persons_Social_security.csv\n",
      "Saved: Datasets\\Government_current_expenditures_Medicare.csv\n",
      "Saved: Datasets\\Federal_government_current_expenditures_Interest_payments.csv\n",
      "Saved: Datasets\\National_Defense_Consumption_Expenditures_and_Gross_Investment.csv\n",
      "Saved: Datasets\\Government_total_expenditures.csv\n",
      "Saved: Datasets\\Federal_Government_Current_Receipts.csv\n"
     ]
    }
   ],
   "source": [
    "# Extrating FRED series and saving it in the path\n",
    "# Create a folder on the actual path to save the files\n",
    "folder_name = \"Datasets\"\n",
    "\n",
    "for index, row in df_sets.iterrows():\n",
    "    series_id = row['Series_Id']\n",
    "    description = row['File_name']\n",
    "    series_name = row['Series_Name']\n",
    "\n",
    "    # Get series data from FRED and save dataframe in a CSV\n",
    "    basedf_fred = fred.get_series(series_id=series_id)\n",
    "    df_fred = pd.DataFrame(basedf_fred, columns=[series_id])\n",
    "    df_fred = df_fred.rename_axis('Date').reset_index()\n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    df_fred = df_fred.set_index('Date').reindex(full_date_range).rename_axis('Date').reset_index()\n",
    "\n",
    "    df_fred[series_id] = df_fred[series_id].bfill()\n",
    "    df_fred[series_id] = df_fred[series_id].ffill()\n",
    "\n",
    "    file_name = os.path.join(folder_name, f\"{description}.csv\")\n",
    "    df_fred.to_csv(file_name, index=False)\n",
    "    print(f\"Saved: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One list for tickers and a dataframe to extract ticker information in the future\n",
    "tickers = data_table[0]['Symbol'].tolist()\n",
    "Sp500_companies = data_table[0][['Symbol', 'Security', 'GICS Sector']]\n",
    "\n",
    "# Making adjustments on the dataset\n",
    "for i in range(len(tickers)):\n",
    "    if tickers[i] == 'BRK.B':\n",
    "        tickers[i] = 'BRK-B'\n",
    "    elif tickers[i] == 'BF.B':  \n",
    "        tickers[i] = 'BF-B'\n",
    "\n",
    "# Adjustments in some ticker codes\n",
    "for index, row in Sp500_companies.iterrows():\n",
    "    if row['Symbol'] == 'BRK.B':\n",
    "        Sp500_companies.at[index, 'Symbol'] = 'BRK-B'\n",
    "    elif row['Symbol'] == 'BF.B':\n",
    "        Sp500_companies.at[index, 'Symbol'] = 'BF-B'\n",
    "\n",
    "ticker_prices = yf.download(tickers, start=start_date, end=end_date)['Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# DXY dataset\n",
    "dxy_df = yf.download('DX-Y.NYB', start=start_date, end=end_date)['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLS series, in this case is inflation, but could extract more than one serie\n",
    "def bls_series(series, start, end, api_key, end_point):\n",
    "\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    payload = {\n",
    "        'seriesid': series, \n",
    "        'startyear': start, \n",
    "        'endyear': end,\n",
    "        'registrationkey': api_key        \n",
    "    }\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.post(end_point, data=data, headers=headers)\n",
    "    json_data = json.loads(response.text)\n",
    "    dfs = []\n",
    "\n",
    "    for serie in json_data['Results']['series']:\n",
    "        df_initial = pd.DataFrame(serie)\n",
    "        series_col = df_initial['seriesID'][0]\n",
    "\n",
    "        for i in range(0, len(df_initial) -1):\n",
    "            df_row = pd.DataFrame(df_initial['data'][i])\n",
    "            df_row['seriesId'] = series_col\n",
    "\n",
    "            if 'code' not in str(df_row['footnotes']):\n",
    "                df_row['footnotes'] = ''\n",
    "            else:\n",
    "                df_row['footnotes'] = str(df_row['footnotes']).split(\"'code': '\", 1)[1][:1]\n",
    "\n",
    "            dfs.append(df_row)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "series = ['CUUR0000SA0']\n",
    "bls_data1 = bls_series(series, 1987, 2006, bls_api_key, BLS_ENDPOINT)\n",
    "bls_data2 = bls_series(series, 2007, 2025, bls_api_key, BLS_ENDPOINT)\n",
    "full_cpi = pd.concat([bls_data1, bls_data2], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new column 'date' in YYYY-MM-DD format\n",
    "full_cpi['Date'] = pd.to_datetime(full_cpi['year'].astype(str) + \n",
    "                                  full_cpi['periodName'], format='%Y%B').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the results by date and creating the dataframe with percent rate of CPI\n",
    "\n",
    "sorted_full_cpi = full_cpi.sort_values(by='Date')\n",
    "sorted_full_cpi['Date'] = pd.to_datetime(sorted_full_cpi['Date'])\n",
    "sorted_full_cpi['value'] = pd.to_numeric(sorted_full_cpi['value'], errors='coerce')\n",
    "sorted_full_cpi.set_index('Date', inplace=True)\n",
    "sorted_full_cpi['CPI Rate'] = float('nan')\n",
    "sorted_full_cpi['CPI Rate'] = sorted_full_cpi['value'].pct_change(periods=12) * 100\n",
    "sorted_full_cpi.reset_index(inplace=True)\n",
    "\n",
    "sorted_full_cpi = sorted_full_cpi[['Date', 'CPI Rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are saved in the folder: Datasets\n"
     ]
    }
   ],
   "source": [
    "# exporting the data - make sure to have 'Datasets' folder on the same path of this file\n",
    "\n",
    "df_SP500.to_csv('Datasets/S&P500.csv', index=False)\n",
    "ticker_prices.to_csv('Datasets/tickers.csv', index=False)\n",
    "Sp500_companies.to_csv('Datasets/Sp500_companies.csv', index=False)\n",
    "sorted_full_cpi.to_csv('Datasets/CPI.csv', index=False)\n",
    "dxy_df.to_csv('Datasets/DXY.csv')\n",
    "\n",
    "print(f\"All files are saved in the folder: {folder_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
